# 🎯 项目深挖 - 面试详解

## 📌 项目背景

**项目名称**: 云原生DevOps平台自动化部署方案  
**技术栈**: Kubernetes 1.28 + Docker + Ansible + GitLab + Jenkins + Harbor + Prometheus + Grafana  
**部署方式**: 基于Ansible的全自动化部署  
**支持模式**: 单节点和多节点部署

---

## 🏗️ 问题1: 架构设计

### Q: 你这个K8s集群是怎么规划的？多少个master/node？网络方案用的什么？

### 📊 集群架构设计

```
【集群规划】
┌─────────────────────────────────────────────────┐
│         Kubernetes 1.28 集群架构                 │
├─────────────────────────────────────────────────┤
│                                                 │
│  Master节点 (1个)                               │
│  ├─ API Server                                  │
│  ├─ Scheduler                                   │
│  ├─ Controller Manager                          │
│  └─ etcd                                        │
│                                                 │
│  Worker节点 (N个)                               │
│  ├─ Kubelet                                     │
│  ├─ Kube-proxy                                  │
│  └─ Container Runtime (Docker/Containerd)      │
│                                                 │
└─────────────────────────────────────────────────┘

### 💡 面试话术

```
"我的K8s集群采用单Master多Worker的架构。

【网络设计】
- 使用Flannel作为CNI插件，提供Pod间通信
- 集群网络192.168.76.0/24用于节点间通信
- Service网络10.96.0.0/12用于服务发现
- Pod网络10.244.0.0/16用于容器通信

【为什么这样设计】
1. Flannel简单易部署，适合学习和小规模集群
2. 三层网络隔离，便于管理和故障排查
3. 支持水平扩展，可以轻松添加Worker节点

【如果要优化】
- 大规模集群可以考虑Calico (更好的网络策略)
- 可以添加多个Master节点实现高可用
- 可以集成Ingress Controller进行流量管理
"
```

---

## 🔄 问题2: CI/CD流程

### Q: 从代码提交到生产部署，完整流程能画个图吗？Jenkins pipeline怎么写的？

### 📈 完整CI/CD流程

```
【代码提交到生产部署的完整流程】

1. 开发者提交代码
   ↓
2. GitLab Webhook触发
   ↓
3. Jenkins Pipeline启动
   ├─ Stage 1: 代码检出 (git clone)
   ├─ Stage 2: 代码构建 (编译/打包)
   ├─ Stage 3: 单元测试 (运行测试)
   ├─ Stage 4: 代码扫描 (SonarQube)
   ├─ Stage 5: 构建镜像 (docker build)
   ├─ Stage 6: 推送镜像 (docker push to Harbor)
   ├─ Stage 7: 更新K8s (kubectl apply)
   └─ Stage 8: 验证部署 (health check)
   ↓
4. 应用在生产环境运行
   ↓
5. Prometheus监控
   ↓
6. 告警系统监控
```



### 💡 面试话术

```
"我的CI/CD流程完全自动化，从代码提交到生产部署只需5-10分钟。

【完整流程】
1. 开发者提交代码到GitLab
2. GitLab Webhook自动触发Jenkins Pipeline
3. Jenkins执行8个阶段:
   - 代码检出、构建、测试
   - 代码扫描、镜像构建
   - 镜像推送到Harbor
   - 更新K8s Deployment
   - 验证部署成功

【关键特性】
- 完全自动化，无需手动干预
- 支持回滚，如果部署失败自动回滚
- 集成了代码质量检查
- 支持多环境部署 (dev/staging/prod)

【如果出现问题】
- Jenkins会立即停止流程
- 发送告警通知开发者
- 保留日志便于排查
"
```

---

## 📊 问题3: 监控告警

### Q: Prometheus采集了哪些指标？Alertmanager的告警规则怎么配的？

### 📈 Prometheus监控指标

```yaml
【采集的关键指标】

1. 系统级指标 (Node Exporter)
   - cpu_usage: CPU使用率
   - memory_usage: 内存使用率
   - disk_usage: 磁盘使用率
   - network_io: 网络I/O
   - disk_io: 磁盘I/O

2. Kubernetes指标
   - kube_pod_info: Pod信息
   - kube_pod_status_phase: Pod状态
   - kube_deployment_status_replicas: Deployment副本数
   - kube_node_status_condition: 节点状态

3. 容器指标 (cAdvisor)
   - container_cpu_usage_seconds_total: 容器CPU使用
   - container_memory_usage_bytes: 容器内存使用
   - container_network_receive_bytes_total: 容器网络接收

4. 应用指标 (自定义)
   - http_requests_total: HTTP请求总数
   - http_request_duration_seconds: 请求延迟
   - application_errors_total: 应用错误数
```
### 💡 面试话术

```
"我的监控系统采用Prometheus + Grafana + Alertmanager的组合。

【采集的指标】
- 系统级: CPU、内存、磁盘、网络I/O
- K8s级: Pod状态、Deployment副本数、节点状态
- 容器级: 容器CPU、内存、网络使用
- 应用级: HTTP请求数、延迟、错误率

【告警规则】
- CPU > 80% 告警
- 内存 > 85% 告警
- 磁盘 > 90% 告警
- Pod频繁重启告警
- 节点不可用告警

【告警分级】
- Critical: 立即通知 (邮件+PagerDuty)
- Warning: 定期通知 (邮件)
- Info: 仅记录日志

【关键特性】
- 告警聚合，避免告警风暴
- 支持自定义告警规则
- 支持多种通知方式
"
```

---

## 🔧 问题4: 故障恢复

### Q: 你说故障恢复5分钟，具体是什么故障？怎么做到的？

### 🚨 常见故障场景

```
【故障场景1: Pod崩溃】
问题: 应用Pod异常退出
恢复时间: 1-2分钟
恢复方式:
  1. Kubelet检测到Pod异常 (10秒)
  2. 自动重启Pod (30秒)
  3. 应用启动完成 (30秒)
  4. 健康检查通过 (30秒)
  总计: ~2分钟

【故障场景2: 节点故障】
问题: Worker节点宕机
恢复时间: 3-5分钟
恢复方式:
  1. K8s检测节点不可用 (40秒)
  2. 驱逐节点上的Pod (30秒)
  3. 在其他节点重新调度 (1分钟)
  4. Pod启动完成 (1分钟)
  总计: ~3-5分钟

【故障场景3: 镜像拉取失败】
问题: Harbor镜像仓库不可用
恢复时间: 2-3分钟
恢复方式:
  1. 检测镜像拉取失败 (30秒)
  2. 自动重试 (1分钟)
  3. 如果Harbor恢复，Pod启动成功 (1分钟)
  总计: ~2-3分钟

【故障场景4: 磁盘满】
问题: 节点磁盘空间不足
恢复时间: 5-10分钟
恢复方式:
  1. 告警系统检测 (1分钟)
  2. 自动清理旧镜像和日志 (2-3分钟)
  3. 如果空间恢复，Pod恢复正常 (2-3分钟)
  总计: ~5-10分钟
```

### 🛠️ 故障恢复机制


3. 节点故障恢复
   - 节点不可用时，Pod自动驱逐到其他节点
   - 支持Pod优先级，关键Pod优先恢复
   - 支持Pod中断预算 (PDB)，保证最小可用副本数
```

### 💡 面试话术

```
"我的系统设计了多层故障恢复机制，确保高可用性。

【故障恢复能力】

1. Pod级别故障 (1-2分钟恢复)
   - 配置了liveness probe，检测到Pod异常立即重启
   - 配置了readiness probe，确保Pod完全就绪才接收流量
   - 部署3个副本，单个Pod故障不影响服务

2. 节点级别故障 (3-5分钟恢复)
   - 节点故障时，K8s自动驱逐Pod到其他节点
   - 配置了Pod反亲和性，避免单点故障
   - 支持自动扩缩容，根据负载调整副本数

3. 应用级别故障 (2-3分钟恢复)
   - 镜像拉取失败时自动重试
   - 支持镜像缓存，加快启动速度
   - 支持灰度发布，新版本问题不影响全量用户

4. 系统级别故障 (5-10分钟恢复)
   - 磁盘满时自动清理旧镜像和日志
   - 告警系统实时监控，及时发现问题
   - 支持自动化运维脚本，快速处理常见问题

【关键指标】
- 平均故障恢复时间 (MTTR): < 5分钟
- 系统可用性 (SLA): > 99.5%
- 故障自动恢复率: > 95%

